{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoatEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render_mods': [None]}\n",
    "\n",
    "    def __init__(self, east_wind=0.25, west_wind=0.25, seed=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            east_wind (float) : Probability of easterly wind\n",
    "        \"\"\"\n",
    "        \n",
    "        assert east_wind + west_wind <= 1, 'Invalid wind probabilities'\n",
    "        \n",
    "        # Only 2 states \"left state or right state\"\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "\n",
    "        # Two possible actions motor on or motor off\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        # Define a random number generator\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        # Probabilities of wind\n",
    "        self.prob_wind = [east_wind, west_wind, 1-east_wind-west_wind]\n",
    "\n",
    "    def get_info(self, wind):\n",
    "        \n",
    "        direction = {0: 'No Wind', 1: 'East Wind', -1:'West Wind'}\n",
    "\n",
    "        if wind is not None:\n",
    "            info = {'Wind': direction[wind]}\n",
    "        else:\n",
    "            info = {'Other News': 'Nothing to report Tom'}\n",
    "\n",
    "        return info\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        # Always start in the left state\n",
    "        self.state = 0\n",
    "        \n",
    "        observation = self.state\n",
    "        info = self.get_info(None)\n",
    "\n",
    "        return observation, info\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        # East +1, No Wind 0, West -1, note wind blows boat plus 1 minus 1 or \n",
    "        # does not move boat at all\n",
    "        wind = self.rng.choice([1, 0, -1], p=self.prob_wind)\n",
    "\n",
    "        # Determine reward (0, 1, 2, 3, or 4)\n",
    "        reward = 2*self.state+1 + wind + action\n",
    "\n",
    "        # Update the state (s')\n",
    "        if self.state == 0: \n",
    "            if reward<2:\n",
    "                self.state = 0\n",
    "            else:\n",
    "                self.state = 1\n",
    "        else:\n",
    "            if reward>2:\n",
    "                self.state = 1\n",
    "            else:\n",
    "                self.state = 0\n",
    "\n",
    "        observation = self.state\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        info = self.get_info(wind)\n",
    "\n",
    "        return observation, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(gym.Env):\n",
    "    def __init__(self, gamma=0.25):\n",
    "        super(GridWorldEnv, self).__init__()\n",
    "        \n",
    "        # Grid dimensions\n",
    "        self.grid_size = (6, 6)\n",
    "        \n",
    "        # Actions: up, down, left, right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # Observations: (i, j) coordinates in the grid\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(self.grid_size[0]),\n",
    "            spaces.Discrete(self.grid_size[1])\n",
    "        ))\n",
    "        \n",
    "        # Define the grid structure\n",
    "        self.walls = [(i, 2) for i in [0, 1]] + [(i, 2) for i in [3, 4, 5]] + [(3, j) for j in [2, 3, 4]]  # Blue walls (bounce off)\n",
    "        # terminal states\n",
    "        self.terminal_states = {\n",
    "            (5, 0): -50,  # Red state\n",
    "            (1, 4): -50,  # Red state\n",
    "            (5, 5): 100   # Green state\n",
    "        }\n",
    "        # step penalty\n",
    "        self.default_reward = -1  # Penalty for each step\n",
    "        \n",
    "        # Movement noise (probability that the action fails and a random action occurs)\n",
    "        self.gamma = gamma\n",
    "        self.rng = np.random.default_rng()\n",
    "        \n",
    "        # Start the agent in the (0, 0) position\n",
    "        self.state = (0, 0)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = (0, 0)\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Introduce noise: the robot might not take the desired action\n",
    "        if self.rng.random() < self.gamma:\n",
    "            action = self.rng.choice([0, 1, 2, 3])  # Random action\n",
    "        \n",
    "        i, j = self.state\n",
    "        \n",
    "        # Move according to action: 0 = Up, 1 = Right, 2 = Down, 3 = Left\n",
    "        if action == 0:  # Up\n",
    "            next_state = (max(i - 1, 0), j)\n",
    "        elif action == 1:  # Right\n",
    "            next_state = (i, min(j + 1, self.grid_size[1] - 1))\n",
    "        elif action == 2:  # Down\n",
    "            next_state = (min(i + 1, self.grid_size[0] - 1), j)\n",
    "        elif action == 3:  # Left\n",
    "            next_state = (i, max(j - 1, 0))\n",
    "        \n",
    "        # Bounce off walls\n",
    "        if next_state in self.walls:\n",
    "            next_state = self.state  # Stay in the same state\n",
    "        \n",
    "        # Assign rewards and check if the agent is in a terminal state\n",
    "        if next_state in self.terminal_states:\n",
    "            reward = self.terminal_states[next_state]\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.default_reward\n",
    "            done = False\n",
    "        \n",
    "        # Update state\n",
    "        self.state = next_state\n",
    "        info = {}\n",
    "        \n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # This is where rendering (like printing the grid) could happen\n",
    "        grid = np.full(self.grid_size, ' ')\n",
    "        grid[self.state] = 'A'  # Mark the agent's position\n",
    "        for wall in self.walls:\n",
    "            grid[wall] = 'W'  # Mark walls\n",
    "        for terminal in self.terminal_states:\n",
    "            if self.terminal_states[terminal] > 0:\n",
    "                grid[terminal] = 'G'  # Green for the goal\n",
    "            else:\n",
    "                grid[terminal] = 'R'  # Red for hazards\n",
    "        \n",
    "        print(\"\\n\".join([\"\".join(row) for row in grid]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
